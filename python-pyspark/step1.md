# Apache Spark

"Apache Sparkâ„¢ is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters." [Apache Spark](https://spark.apache.org)

Spark is a unified analytics engine for big data and machine learning.

## Why should I use Spark?

Spark can be up to 100x faster than Hadoop on processing large amounts of data. Furthermore, Spark has easy-to-use APIs with over 100 operators for working with data. It also includes support for higher-level operations like SQL queries, streaming data and machine learning.

## How can I use Spark?

Spark provides APIs for different programming languages lik Python, Java and R.


---
Now that you learned what Apache Spark is we will take a look at using Python and PySpark for operations in the following scenarios.
