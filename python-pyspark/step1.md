"Apache Sparkâ„¢ is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters." [Apache Spark](https://spark.apache.org)

Spark is a unified analytics engine for big data and machine learning. It is the most widely used engine for scalable computing with thousands of companies using Apache Spark [1].

## Benefits of Spark

Spark can be up to 100x faster than Hadoop on processing large amounts of data. Furthermore, Spark has easy-to-use APIs with over 100 operators for working with data. It also includes support for higher-level operations like SQL queries, streaming data and machine learning [2].

## Spark Use cases

Spark has many use cases in the field of big data, data warehouse and machine learning [3]:

- Batch Processing
- High performance computing on clusters
- Microstreaming and near real-time processing
- Interactive data analysis and discovery

## Spark API

Apache Spark is written in Scala programming language but provides APIs for different programming languages like Python, Java and R [1]. This allows administrators and developers to use Spark flexible in the programming languages they use so far in their applications.

---
Now that you've learned in short what Apache Spark is, we will take a look at using Python and PySpark for data operations in the following scenarios.

---

## Sources

[1] Apache Spark. [Online]. Available: https://spark.apache.org <br />
[2] PySpark - Introduction. [Online]. Available: https://www.tutorialspoint.com/pyspark/pyspark_introduction.htm  <br />
[3] Buckenhofer, A. (2022). T3INF4304-3 Lecture @DHBW: Data Warehouse 04 Tools
 [Powerpoint Slides]. DHBW Stuttgart lecture