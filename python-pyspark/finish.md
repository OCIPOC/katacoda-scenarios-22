Congrats! You've finished the katacoda "pyspark".

Throughout this katacoda scenario, you learned what Apache Spark is and how you can use pyspark with datasets. You got a little insight into the possibilities of pyspark for data processing. You learned at how to load a dataset from a file, how you can analyse the data and how to transform data stored in a pyspark DataFrame.

Below you can find a list of all sources and references used in this scenario.

# Sources

[1] Apache Spark. [Online]. Available: https://spark.apache.org <br />
[2] PySpark - Introduction. [Online]. Available: https://www.tutorialspoint.com/pyspark/pyspark_introduction.htm  <br />
[3] Buckenhofer, A. (2022). T3INF4304-3 Lecture @DHBW: Data Warehouse 04 Tools [Powerpoint Slides]. DHBW Stuttgart lecture <br />
[4] Quickstart: DataFrame. [Online]. Available: https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html <br />
[5] Spark with Python (PySpark) Tutorial For Beginners. [Online]. Available: https://sparkbyexamples.com/pyspark-tutorial/ <br />
[6] Apache Spark Tutorial â€” How to Read and Write Data With PySpark. [Online]. Available: https://towardsdatascience.com/spark-essentials-how-to-read-and-write-data-with-pyspark-5c45e29227cd <br />
[7] Useful PySpark SQL Functions for a Quick Start. [Online]. Available: https://towardsdev.com/useful-pyspark-sql-functions-for-a-quick-start-aae31d422a31 <br />
[8] Pandas vs PySpark DataFrame With Examples. [Online]. Available: https://sparkbyexamples.com/pyspark/pandas-vs-pyspark-dataframe-with-examples/